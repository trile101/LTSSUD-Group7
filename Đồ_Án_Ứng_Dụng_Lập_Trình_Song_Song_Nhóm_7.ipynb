{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1>Đồ án Cuối Kì - Ứng Dụng Lập Trình Song Song<h1></center>"
      ],
      "metadata": {
        "id": "BdBYStbqUQo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Thông tin thành viên nhóm"
      ],
      "metadata": {
        "id": "a7oOYjQezreb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  |  Nhóm |MSSV | Họ và Tên|\n",
        "| --- | ---| -------- | ----------- |\n",
        "| 1 | Nhóm 7|19127353 | Lê Tấn Đạt|\n",
        "| 2 | Nhóm 7|19127593 | Lê Tiến Trí|"
      ],
      "metadata": {
        "id": "8v3YYEEuzsO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Link Github"
      ],
      "metadata": {
        "id": "6I_0LSxiB8_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link github của nhóm: https://github.com/trile101/LTSSUD-Group7"
      ],
      "metadata": {
        "id": "mNeYYGQXCGH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Mô tả bài toán và tập dữ liệu."
      ],
      "metadata": {
        "id": "oRyl5yK7COFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mô tả bài toán:\n",
        "- Phân loại chữ số viết tay là một bài toán thuộc mảng Computer Vision, bài toán này đã giới thiệu từ rất lâu và hiện nay có rất nhiều mô hình đã giải quyết hiệu quả đạt được độ chính xác rất cao. Trong đó, bộ dữ liệu MNIST là bộ dữ liệu được sử dụng nhiều nhất cho bài toán này.\n",
        "      \n",
        "- Nhóm quyết định giải quyết bài toán phân loại chữ số viết tay MNIST bằng Convolutional Neural Network, kết hợp với kĩ thuật lập trình song song để tăng tốc quá trình huấn luyện.\n",
        "\n",
        "- Mô hình mà nhóm hướng tới để thực hiện đó là mô hình CNN, sẽ được trình bày rõ hơn ở phần sau."
      ],
      "metadata": {
        "id": "poXr22S5dFzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset, input và output của bài toán\n",
        "- Bộ dữ liệu MNIST(Modified National Institute of Standards and Technology) là một bộ dữ liệu lớn chứa các chữ số viết tay thường được dùng trong việc huấn luyện các hệ thống xử lí hình ảnh, bao gồm 2 tập con: training set gồm 60.000 ảnh các chữ số viết tay và test set gồm 10.000 ảnh các chữ số.\n",
        "MNIST nổi tiếng vì tần suất mà bộ dữ liệu được sử dụng.\n",
        "- Bộ dữ liệu bao gồm 70.000 hình ảnh của các chữ số viết tay với sự phân chia như sau:\n",
        "    - 60.000 hình ảnh đào tạo (training)\n",
        "    - 10.000 hình ảnh thử nghiệm (testing)\n",
        "- Input của bài toán:\n",
        "    - ![](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/5.png?w=308&ssl=1)\n",
        "    - Là một ảnh xám 28x28 pixel gồm các chữ số đơn viết tay từ 0 đến 9.\n",
        "- Output: phân loại chính xác con số được biểu thị bởi hình input.\n",
        "- Ví dụ ở đây với input như trên thì ta kì vọng output sẽ là 5."
      ],
      "metadata": {
        "id": "f-k4XIXnMFz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Những gì đã hoàn thành được đối với cả nhân và cả nhóm"
      ],
      "metadata": {
        "id": "RnoymYqqdebE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Lê Tấn Đạt: 19127353**:\n",
        "    - Implement phiên bản tuần tự của thuật toán CNN cho tập dữ liệu MNIST\n",
        "    - Nghiên cứu các giải pháp song song hoá thuật toán tuần tự\n",
        "- **Lê Tiến Trí: 19127593**:\n",
        "    - Implement phiên bản song song của thuật toán CNN cho tập dữ liệu MNIST\n",
        "    - Nghiên cứu các giải pháp song song hoá thuật toán tuần tự\n",
        "- Cả nhóm:\n",
        "    - Đã hoàn thành phiên bản tuần tự của thuật toán CNN.\n",
        "    - Đã hoàn thành phiên bản song song hoá của thuật toán CNN.\n",
        "    - Có 3 layer cần song song hoá: Convolutional Layer, Maxpooling layer và Fully Connected Layer. Đã song song hoá Convolutional Layer, đối với Maxpooling layer và Fully Connected layer thì nhóm sử dụng decorator jit(parallel=True) và jit(nopython = true) để tăng tốc độ chạy của thuật toán song song."
      ],
      "metadata": {
        "id": "z6Q93b1HOJJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numba\n",
        "from numba import jit, prange, cuda\n",
        "from numba import config\n",
        "config.THREADING_LAYER = 'omp'\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import timeit\n",
        "import time\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "C0GIpE3WTeG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7FcZrgiObbN"
      },
      "source": [
        "## IV. Thuật toán tuần tự, code và đánh giá"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mô hình chính của bài toán đó là mô hình CNN, cụ thể các lớp sẽ được implement trong mô hình bao gồm:\n",
        "    - Convolution Layer\n",
        "    - Maxpooling Layer\n",
        "    - Flatten Layer\n",
        "    - Fully Connected Layer\n",
        "    - Relu Layer\n",
        "    - Softmax Layer\n",
        "- Cùng với đó là hàm tính độ lỗi đối với bài toán phân loại có nhiều hơn 2 lớp đó **categorical_crossentropy**"
      ],
      "metadata": {
        "id": "kkKgJkAyQUQG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwpUj0z8OtQH"
      },
      "source": [
        "### Class Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Base class để các layer khác kế thừa, khi cần train mô hình chỉ cần gọi hàm forward, backward."
      ],
      "metadata": {
        "id": "nQBZhA8-QCX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1ybKpV7FL4k"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        # TODO: return output\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        # TODO: update parameters and return input gradient\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntHWlYMUFS1t"
      },
      "source": [
        "### CNN Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Minh hoạ:\n",
        "\n",
        "![](https://topdev.vn/blog/wp-content/uploads/2019/08/Convolution_schematic.gif)\n",
        "- Giải thích về lớp **Convolutional**: Lớp này là lớp đầu tiên được sử dụng để trích xuất các đặc trưng từ các hình ảnh đầu vào. Trong lớp này, phép toán tích chập được thực hiện giữa hình ảnh đầu vào và một số lượng filter có kích thước cụ thể MxM. Ta trượt bộ lọc qua hình ảnh đầu vào, tính dot product giữa bộ lọc và các phần của hình ảnh đầu vào tương ứng với kích thước của bộ lọc (MxM).\n",
        "- Input đầu vào: ảnh xám input có kích thước 28*28, filter có kích thước 3x3, depth là số lượng filter sẽ sử dụng. (28x28)\n",
        "- Output: ảnh vuông mới có kích thước là (28-3+1 = 26). Do có 3 filter được sử dụng do đó kịch thước output sẽ là (26, 26 ,3)"
      ],
      "metadata": {
        "id": "gKIj39nxRnXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code"
      ],
      "metadata": {
        "id": "5xdfWVijUAjW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QVC0zvSFZgl"
      },
      "outputs": [],
      "source": [
        "class Convolutional(Layer):\n",
        "    def __init__(self, input_shape, kernel_size, depth):\n",
        "        input_depth, input_height, input_width = input_shape\n",
        "        self.depth = depth\n",
        "        self.input_shape = input_shape\n",
        "        self.input_depth = input_depth\n",
        "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
        "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
        "        np.random.seed(0)\n",
        "        self.kernels = np.random.randn(*self.kernels_shape)\n",
        "        np.random.seed(0)\n",
        "        self.biases = np.random.randn(*self.output_shape)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = np.copy(self.biases)\n",
        "        for i in range(self.depth):\n",
        "            for j in range(self.input_depth):\n",
        "                self.output[i] += signal.correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        kernels_gradient = np.zeros(self.kernels_shape)\n",
        "        input_gradient = np.zeros(self.input_shape)\n",
        "\n",
        "        for i in range(self.depth):\n",
        "            for j in range(self.input_depth):\n",
        "                kernels_gradient[i, j] = signal.correlate2d(self.input[j], output_gradient[i], \"valid\")\n",
        "                input_gradient[j] += signal.convolve2d(output_gradient[i], self.kernels[i, j], \"full\")\n",
        "\n",
        "        self.kernels -= learning_rate * kernels_gradient\n",
        "        self.biases -= learning_rate * output_gradient\n",
        "        return input_gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j749mRDVF-TO"
      },
      "source": [
        "### Maxpooling Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Minh hoạ:\n",
        "\n",
        "![](https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png)\n",
        "- Giải thích về lớp **Maxpooling**:\n",
        "    - Thao tác pooling bao gồm việc trượt một bộ lọc hai chiều trên mỗi kênh của input và tóm tắt các đặc trưng nằm trong vùng được bao phủ bởi bộ lọc.\n",
        "    - Có hai thao tác pooling thường gặp: maxpooling (lấy max) và average pooling ( lấy giá trị trung bình).\n",
        "    - Lớp pooling sẽ giảm bớt số lượng tham số khi hình ảnh quá lớn. Không gian pooling còn được gọi là lấy mẫu con hoặc lấy mẫu xuống làm giảm kích thước của mỗi map nhưng vẫn giữ lại thông tin quan trọng.\n",
        "- Input đầu vào: ảnh xám input có kích thước 26*26, filter có kích thước 2x2, stride là 2.\n",
        "- Output: ảnh vuông mới có kích thước là (13, 13)"
      ],
      "metadata": {
        "id": "6qIC8bT4UFfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPjxHcl_GF2V"
      },
      "outputs": [],
      "source": [
        "class MaxPoolingLayer(Layer):\n",
        "  def __init__(self, input_shape, kernel_size, stride):\n",
        "\n",
        "      input_depth, input_height, input_width = input_shape\n",
        "      self.depth = input_depth\n",
        "      self.stride = stride\n",
        "      self.input_shape = input_shape\n",
        "      self.output_shape = (self.depth, int((input_height - kernel_size) / stride) + 1, int((input_width - kernel_size) / stride) + 1)\n",
        "      self.kernels_size = kernel_size\n",
        "\n",
        "      self.prev_input = np.zeros(input_shape)\n",
        "\n",
        "\n",
        "  def get_pools(self, input, depth):\n",
        "\n",
        "      pools = []\n",
        "\n",
        "      for i in np.arange(input.shape[0], step=self.stride):\n",
        "\n",
        "          for j in np.arange(input.shape[1], step=self.stride):\n",
        "\n",
        "              mat = input[i:i+self.kernels_size, j:j+self.kernels_size]\n",
        "\n",
        "              if mat.shape == (self.kernels_size, self.kernels_size):\n",
        "\n",
        "                 pools.append(np.max(mat))\n",
        "\n",
        "                 idx = np.where(input[i:i+self.kernels_size,j:j+self.kernels_size] == np.max(mat)) # find index where max element store in.\n",
        "                 self.prev_input[depth][i + idx[0][0],j + idx[1][0]] = input[i + idx[0][0],j + idx[1][0]] # store in prev_input.\n",
        "\n",
        "\n",
        "      tgt_shape = (self.output_shape[1], self.output_shape[2])\n",
        "      return np.array(pools).reshape(tgt_shape)\n",
        "\n",
        "  def max_pooling(self, input):\n",
        "\n",
        "      num_pools = input.shape[1]\n",
        "      tgt_shape = (self.output_shape[1], self.output_shape[2])\n",
        "      pooled = []\n",
        "\n",
        "      for pool in input:\n",
        "          pooled.append(np.max(pool))\n",
        "\n",
        "      return np.array(pooled).reshape(tgt_shape)\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    self.output = np.zeros(self.output_shape)\n",
        "    for i in range(self.depth):\n",
        "        self.output[i] = self.get_pools(self.input[i], i)\n",
        "\n",
        "    return self.output\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "      return self.prev_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx33JDJ6Ewi-"
      },
      "source": [
        "### Flatten Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Output của CNN có dạng ma trận (2 chiều), ta cần phải \"trải phẳng\" ra trước khi đưa qua lớp Fully Connected. Do đó, ta cần một layer gọi là Reshape để thay đổi shape sang hình dạng 1 chiều."
      ],
      "metadata": {
        "id": "YtXVTzI1Vlxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0wHT1IGE6K8"
      },
      "outputs": [],
      "source": [
        "class Reshape(Layer):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        self.input_shape = input_shape\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, self.output_shape)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        return np.reshape(output_gradient, self.input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyG1mrNeRAUk"
      },
      "source": [
        "### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Minh hoạ:\n",
        "\n",
        "![](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/2_fully-connected-layer.jpg)\n",
        "- Giải thích về lớp **Fully Connected**:\n",
        "    - Tầng kết nối đầy đủ (FC) nhận đầu vào là các dữ liệu đã được làm phẳng, mà mỗi đầu vào đó được kết nối đến tất cả neuron.\n",
        "    - Tầng này có chức năng chuyển ma trận đặc trưng ở tầng trước thành vector chứa xác suất của các đối tượng cần được dự đoán. Ví dụ, trong bài toán phân loại số viết tay MNIST có 10 lớp tương ứng 10 số từ 0-1, tầng fully connected layer sẽ chuyển ma trận đặc trưng của tầng trước thành vector có 10 chiều thể hiện xác suất của 10 lớp tương ứng.\n",
        "    - Công thức tính cho lớp Fully Connected:\n",
        "\n",
        "        - ![](https://camo.githubusercontent.com/ea0bc2fad6c8958479956280d8bace2b146f3ec4ce31e0de13b672b99629bce4/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f3637342f302a4563396669586b4e4f6f41355a3276352e706e67)\n",
        "        - Trong đó ```b``` là bias, ```w``` là weights (trọng số được khởi tạo mỗi khi gọi đến Layer)\n",
        "\n",
        "- Input đầu vào: ảnh xám input có kích thước Mx1,\n",
        "- Output: ảnh vuông mới có kích thước tuỳ chỉnh."
      ],
      "metadata": {
        "id": "lKK9omZDV59P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShcTb24RHC-l"
      },
      "outputs": [],
      "source": [
        "class FCLayer(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.random.randn(output_size, input_size)\n",
        "        self.bias = np.random.randn(output_size, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(self.weights, self.input) + self.bias\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.bias -= learning_rate * output_gradient\n",
        "        return input_gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Is2TnKVRtax"
      },
      "source": [
        "### Relu Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Minh hoạ:\n",
        "    ![](https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-05dbf7c989503746df6a2204dbf5a36a_l3.svg)\n",
        "- Giải thích về hàm **Relu**:\n",
        "    - Trong mạng thần kinh, hàm kích hoạt chịu trách nhiệm chuyển đổi đầu vào có trọng số tổng từ nút thành kích hoạt nút hoặc đầu ra cho đầu vào đó.\n",
        "    - Hàm kích hoạt tuyến tính được chỉnh lưu (Rectified Linear Unit) hay được gọi là ReLU là một hàm tuyến tính từng phần sẽ xuất đầu vào trực tiếp nếu nó dương, nếu không, nó sẽ xuất ra số 0.\n",
        "    - Hầu hết người ta thường dùng ReLU cho mô hình CNN vì nó có hiệu suất tốt."
      ],
      "metadata": {
        "id": "2z9fs9XmXgDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLUgfhviHJtV"
      },
      "outputs": [],
      "source": [
        "class Relu(Layer):\n",
        "    def __init__(self, alpha = 0.1):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs.copy()\n",
        "        self.outputs = np.maximum(0, inputs)\n",
        "        return self.outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        self.input_gradient = output_gradient.copy()\n",
        "        self.input_gradient[self.inputs < 0] = 0\n",
        "        return self.input_gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu9NcR2Cmoq6"
      },
      "source": [
        "### Softmax layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Vì đây là bài toán phân loại với số lượng lớp lớn hơn 2 (10 lớp) do đó hàm Softmax sẽ được sử dụng ngay sau lớp Fully Connected để tính toán ra được xác xuất của từng lớp đối với input đầu vào.\n",
        "- Hàm softmax có hai đặc tính:\n",
        "    - Xác suất sẽ luôn nằm trong khoảng (0:1].\n",
        "    - Tổng tất cả các xác suất bằng 1.\n",
        "- Nguyên lý của hàm  Softmax đối với một vài số cho trước:\n",
        "    - Tính hàm lũy thừa số e, với số mũ là những số đã cho\n",
        "    - Tính tổng các lũy thừa đó. Đó sẽ là mẫu số.\n",
        "    - Sử dụng lũy thừa của mỗi số là tử số\n",
        "    - Xác suất sẽ là tử số/mẫu số\n",
        "    - Công thức hàm Softmax:\n",
        "\n",
        "        ![](https://lh3.googleusercontent.com/5WZx0XW3sYFI7iQ8qP09vrAatoBGXtkVLs8H40FhrrNhu0TKH-W7mcMWGaH84S5CcJfx_aS_7U49H_6Lvfu056iZH9fUtKvuFOliMx81egv2MnIEjm9zOsWS4VNx2e2MZoows17j)"
      ],
      "metadata": {
        "id": "TMr9JeKOYljX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu1s861PniuI"
      },
      "outputs": [],
      "source": [
        "class Softmax(Layer):\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        tmp = np.exp(self.input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        n = np.size(self.output)\n",
        "        return np.dot((np.identity(n) - self.output.T) * self.output, output_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EpxujbR2YV"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCl_IK0jSRSG"
      },
      "outputs": [],
      "source": [
        "def categorical_crossentropy(y_true, y_pred):\n",
        "    return -np.sum(y_true * np.log(y_pred + 10**-100))\n",
        "\n",
        "def categorical_crossentropy_backpropagation(y_true, y_pred):\n",
        "    return -y_true/(y_pred + 10**-100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN9tW4DtSPnE"
      },
      "source": [
        "### Xây dựng Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPvlor-wSWcd"
      },
      "outputs": [],
      "source": [
        "def predict(network, input):\n",
        "    output = input\n",
        "    fc_time = 0\n",
        "    for layer in network:\n",
        "        start = time.time()\n",
        "        output = layer.forward(output)\n",
        "        end = time.time()\n",
        "        layer_time = end - start\n",
        "        if layer.__class__.__name__ == \"Convolutional\":\n",
        "            conv_time = layer_time\n",
        "        if layer.__class__.__name__ == \"MaxPoolingLayer\":\n",
        "            pool_time = layer_time\n",
        "        if layer.__class__.__name__ == \"FCLayer\":\n",
        "            fc_time += layer_time\n",
        "    return output, conv_time, pool_time, fc_time\n",
        "\n",
        "def predict_test(network, x_test, y_test, verbose = True):\n",
        "    error = 0\n",
        "    y_pred = y_test[0]\n",
        "    true_label = 0\n",
        "\n",
        "    for x, y in zip(x_test, y_test):\n",
        "        output = x\n",
        "        for layer in network:\n",
        "            output = layer.forward(output)\n",
        "        y_pred = output\n",
        "\n",
        "        if np.argmax(y_pred) == np.argmax(y):\n",
        "            true_label += 1\n",
        "\n",
        "        # error\n",
        "        error += categorical_crossentropy(y, y_pred)\n",
        "\n",
        "        # backward\n",
        "        grad = categorical_crossentropy_backpropagation(y, y_pred)\n",
        "        for layer in reversed(network):\n",
        "            grad = layer.backward(grad, 0.1)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Accuracy Score = {true_label/y_test.shape[0]}\")\n",
        "\n",
        "\n",
        "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000, learning_rate = 0.01, verbose = True):\n",
        "\n",
        "    for e in range(epochs):\n",
        "        total_time_conv = 0\n",
        "        total_time_pool = 0\n",
        "        total_time_fc = 0\n",
        "        start = time.time()\n",
        "        error = 0\n",
        "        for x, y in zip(x_train, y_train):\n",
        "            # forward\n",
        "            output, ct, pt, fct = predict(network, x)\n",
        "            total_time_conv += ct\n",
        "            total_time_pool += pt\n",
        "            total_time_fc += fct\n",
        "\n",
        "            # error\n",
        "            error += loss(y, output)\n",
        "\n",
        "            # backward\n",
        "            grad = loss_prime(y, output)\n",
        "            for layer in reversed(network):\n",
        "                grad = layer.backward(grad, learning_rate)\n",
        "\n",
        "        end = time.time()\n",
        "        error /= len(x_train)\n",
        "        if verbose:\n",
        "            print(f\"{e + 1}/{epochs}, error={error}, time={end-start}\")\n",
        "            print(f\"Total Convolution Time={total_time_conv}\")\n",
        "            print(f\"Total MaxPooling Time={total_time_pool}\")\n",
        "            print(f\"Total FullyConnected Time={total_time_fc}\")\n",
        "            print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQfV8qkXIJu9"
      },
      "outputs": [],
      "source": [
        "network = [\n",
        "    Convolutional((1, 28, 28), 3, 5),\n",
        "    Relu(),\n",
        "    MaxPoolingLayer((5,26,26), 2, 2),\n",
        "    Reshape((5, 13, 13), (5 * 13 * 13, 1)),\n",
        "    FCLayer(5 * 13 * 13, 100),\n",
        "    Softmax(),\n",
        "    FCLayer(100, 10),\n",
        "    Softmax()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Isk-qUtIW5c"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(x, y,limit=60000):\n",
        "    x = x.reshape(len(x), 1, 28, 28)[:limit]\n",
        "    y = np_utils.to_categorical(y)\n",
        "    y = y.reshape(len(y), 10, 1)[:limit]\n",
        "    return x/255.0, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDTdWKz5IddF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ab685a-b857-48a8-af82-5e1a9a2de0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train = preprocess_data(x_train, y_train,30000)\n",
        "x_test, y_test = preprocess_data(x_test, y_test,10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVMsikfiqQId",
        "outputId": "9ee2b28d-31a0-4553-91d8-3e790baf086a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000, 1, 28, 28), (30000, 10, 1), (10000, 1, 28, 28), (10000, 10, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqp1CcSKOu92",
        "outputId": "b7f9b85e-fdda-46e4-e26e-71c6ca8f1864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "np.seterr(divide = 'ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcDzDEnyIM7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851049a5-7cbe-45ea-ae64-e4e74aee82a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5, error=2.3322510242131202, time=863.6049616336823\n",
            "Total Convolution Time=12.570622444152832\n",
            "Total MaxPooling Time=765.5276916027069\n",
            "Total FullyConnected Time=23.04584789276123\n",
            "\n",
            "2/5, error=2.3311105205075466, time=844.9227902889252\n",
            "Total Convolution Time=11.976377010345459\n",
            "Total MaxPooling Time=739.7580983638763\n",
            "Total FullyConnected Time=27.319246768951416\n",
            "\n",
            "3/5, error=2.331050419926125, time=838.0970630645752\n",
            "Total Convolution Time=11.870171070098877\n",
            "Total MaxPooling Time=733.2512247562408\n",
            "Total FullyConnected Time=27.475435495376587\n",
            "\n",
            "4/5, error=2.33101046837945, time=837.993923664093\n",
            "Total Convolution Time=11.92070460319519\n",
            "Total MaxPooling Time=733.2336919307709\n",
            "Total FullyConnected Time=27.340416431427002\n",
            "\n",
            "5/5, error=2.330980728993, time=833.4096159934998\n",
            "Total Convolution Time=11.762924432754517\n",
            "Total MaxPooling Time=729.327478647232\n",
            "Total FullyConnected Time=26.972058296203613\n",
            "\n",
            "CPU times: user 1h 11min 29s, sys: 50min 36s, total: 2h 2min 5s\n",
            "Wall time: 1h 10min 18s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train(\n",
        "    network,\n",
        "    categorical_crossentropy,\n",
        "    categorical_crossentropy_backpropagation,\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    learning_rate=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "predict_test(\n",
        "    network,\n",
        "    x_test,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qqSzhaf2TeI",
        "outputId": "0c51417a-d968-4669-cc16-f383b3934573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.816\n",
            "CPU times: user 4min 44s, sys: 3min 20s, total: 8min 5s\n",
            "Wall time: 4min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtNFkgx_Ojmt"
      },
      "source": [
        "## V. Cài đặt song song\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Ý tưởng phát triển bài toán"
      ],
      "metadata": {
        "id": "7Ri0fVQ9zzfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau quá trình đánh giá và nghiên cứu, nhóm tiến hành thực hiện áp dụng thư viện `numba` để phát triển song song ở một số layer và áp dụng sức mạnh của numba để tăng tốc độ của một số layer trong CNN."
      ],
      "metadata": {
        "id": "cVFwJeqsz0ZN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNnLoC-W9dPq"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1KQRGSqkREcdAYSht-ZnQTYAkknoECTY0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Với mô hình mạng `Convolution Neural Network` kết hợp với numba của python**\n",
        "- `Lớp CNN` - sử dụng `numba(cuda.jit)`: Để thực hiện quá trình chạy song song trên GPU để tăng tốc độ của lớp này\n",
        "- `Lớp Relu`, `MaxPooling`, `Fully Connected`, `Softmax`, `Category Cross Entropy` - sử dụng `numba(nonpython=True)`: Các lớp này sẽ được làm lại để có kết hợp với numba để tăng tốc so với lớp sử dụng thư viện numpy ban đầu"
      ],
      "metadata": {
        "id": "XpQgmPgWz3d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import jit, prange, cuda\n",
        "from numba import config\n",
        "config.THREADING_LAYER = 'omp'\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import timeit\n",
        "import time"
      ],
      "metadata": {
        "id": "NE4APAT5ddH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(x, y,limit=60000):\n",
        "    x = x.reshape(len(x), 28, 28,1)[:limit]\n",
        "    y = np_utils.to_categorical(y)\n",
        "    y = y.reshape(len(y), 10)\n",
        "    return x/255.0, y"
      ],
      "metadata": {
        "id": "SGz5fOF6e7fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "fVltXc9Te7io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8016a99-2980-4ae2-ea5b-659566d9011b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train=preprocess_data(x_train, y_train, 30000)\n",
        "x_test, y_test = preprocess_data(x_test, y_test, 10000)"
      ],
      "metadata": {
        "id": "YE6snpuOe7lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        # TODO: return output\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        # TODO: update parameters and return input gradient\n",
        "        pass"
      ],
      "metadata": {
        "id": "HCbPgW3Ye7oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Layer"
      ],
      "metadata": {
        "id": "sIetzQkojHw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ý tưởng và thiết kế CNN:**\n",
        "- Trong quá trình huấn luyện CNN, ta truyền vào mini-batch nhất định, nên ta sẽ chia `grid_size = (số lượng ảnh input, số channel input)` từng ứng -> Nhằm mục đích với mỗi block sẽ xử lí một ảnh chỉ có chứa 1 channel duy nhất.\n",
        "- Với mỗi block thì sẽ cho kích thước tương ứng với mỗi giai đoạn cần xử lí:\n",
        "  - Hàm `convolve_forward` sẽ có block_size là (output_height, output width).\n",
        "    - Hàm `backward_input` sẽ có block_size là (input height, input width).\n",
        "    - Hàm `backward_kernel` sẽ có block_size là (output_gradient height, output_gradient width)"
      ],
      "metadata": {
        "id": "U5mH2NfR0ARd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Lan truyền tiến"
      ],
      "metadata": {
        "id": "0Up3yjzz0ERn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Với mỗi thread sẽ thực hiện nhiệm vụ của mỗi điểm ảnh output"
      ],
      "metadata": {
        "id": "kz5APfDF0pb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1qcUABIwnXdO-uGKEZMOkGMsEhzGykugj)"
      ],
      "metadata": {
        "id": "H70efENc2wT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve_forward_device(imgs, filter, bias, output):\n",
        "  '''\n",
        "  Function - Áp dụng tính tổng tích các điểm giữa 2 ma trận trên ảnh và filter với kích thước (filter.width, filter.height, filter.layer) để có thể tính ra điểm output trên mỗi thread\n",
        "  '''\n",
        "  tx = cuda.threadIdx.x\n",
        "  ty = cuda.threadIdx.y\n",
        "  ff = cuda.blockIdx.y\n",
        "  ii = cuda.blockIdx.x\n",
        "\n",
        "  for c_img in range(filter.shape[1]):\n",
        "      for hh in range(filter.shape[2]):\n",
        "        for ww in range(filter.shape[3]):\n",
        "          imgval = imgs[ii, ty + hh, tx + ww, c_img]\n",
        "          filterval = filter[ff,c_img, hh, ww]\n",
        "          output[ii, ty, tx, ff] += imgval * filterval\n",
        "  output[ii, ty, tx, ff] += bias[ty,tx,ff]"
      ],
      "metadata": {
        "id": "kY9NxljRe7rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Lan truyền ngược"
      ],
      "metadata": {
        "id": "4XdTQPWF0PM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1iD5nQB2g3LlIbI6Pk9uQT5Bds3KgwOPM"
      ],
      "metadata": {
        "id": "qpSQyY6mAsnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Quá trình lan truyền ngược: Sau khi nhận được gradient của lớp sau truyền vào thì lớp Convolution sẽ bao gồm 2 bước:\n",
        "  - Bước 1: Lớp convolution sẽ sử dụng gradient được truyền vào để đi tính lại bộ trọng số của bộ lọc để giảm thiểu sai số\n",
        "  - Bước 2: Sẽ đi tính gradient sau khi bộ trọng số được cập nhật để cho lớp trước đó sử dụng\n",
        "- Dựa vào các bước đó, ta chia song song hóa của quá trình lan truyền ngược làm 2 phần\n",
        "  - Phần 1 (backward_kernel_device): Ta sẽ dựa theo công thức để áp dụng cho từng điểm trên filter\n",
        "  ![picture](https://drive.google.com/uc?export=view&id=1LrQgZpbltmqIEs8nN7LYha8h7wDykqgm)\n",
        "  - Phần 2 (backward_input_device): Ta sẽ dựa theo công thức để áp dụng cho từng điểm trên filter\n",
        "  ![picture](https://drive.google.com/uc?export=view&id=1iD5nQB2g3LlIbI6Pk9uQT5Bds3KgwOPM)"
      ],
      "metadata": {
        "id": "eoBhA7au7VE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def backward_kernel_device(input, output_gradient, output):\n",
        "  '''\n",
        "  Function - Tính đạo hàm của mỗi lớp filter theo hàm loss dựa trên input và gradient của lớp trước\n",
        "  '''\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    ii = cuda.blockIdx.x\n",
        "    ff = cuda.blockIdx.y\n",
        "    n_imgs = input.shape[0]\n",
        "\n",
        "    for c_img in range(input.shape[3]):\n",
        "        for hh in range(output.shape[2]):\n",
        "          for ww in range(output.shape[3]):\n",
        "            temp = input[ii, ty + hh, tx + ww, c_img] * output_gradient[ii, ty, tx , ff] / n_imgs\n",
        "            output[ff, c_img, hh, ww] += temp\n",
        "\n",
        "@cuda.jit\n",
        "def backward_input_device(output_gradient, kernel, output):\n",
        "  '''\n",
        "  Function - Tính đạo hàm của mỗi lớp input theo hàm loss dựa trên filter và gradient của lớp trước\n",
        "  '''\n",
        "  tx = cuda.threadIdx.x\n",
        "  ty = cuda.threadIdx.y\n",
        "  ii = cuda.blockIdx.x\n",
        "  c_img = cuda.blockIdx.y\n",
        "\n",
        "  for ff in range(kernel.shape[0]):\n",
        "    for hh in range(kernel.shape[2]):\n",
        "      for ww in range(kernel.shape[3]):\n",
        "          temp = output_gradient[ii, ty + hh, tx + ww, ff] * kernel[ff, c_img, hh, ww]\n",
        "          output[ii, ty, tx, c_img] += temp"
      ],
      "metadata": {
        "id": "ZAZ1NQMu0IQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C. Class - Convolution"
      ],
      "metadata": {
        "id": "_sjVrEIQ0ctI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNLayer_Device(Layer):\n",
        "    def __init__(self, input_shape, kernel_size, depth):\n",
        "        input_depth, input_height, input_width = input_shape\n",
        "\n",
        "        self.depth = depth\n",
        "        self.input_shape = input_shape\n",
        "        self.input_depth = input_depth\n",
        "\n",
        "        self.output_shape = (input_height - kernel_size + 1, input_width - kernel_size + 1,depth)\n",
        "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
        "\n",
        "        np.random.seed(10)\n",
        "        self.kernels = np.random.randn(*self.kernels_shape)\n",
        "        np.random.seed(10)\n",
        "        self.biases = np.random.randn(*self.output_shape)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Phân bố số lượng kích thước của grid và block\n",
        "        self.input = input\n",
        "        self.output = np.zeros((input.shape[0], self.output_shape[0], self.output_shape[1], self.output_shape[2]))\n",
        "        grid_size = (input.shape[0], self.depth)\n",
        "        block_size = (self.output.shape[1], self.output.shape[2])\n",
        "        # Copy dữ liệu từ CPU sang GPU\n",
        "        d_in = cuda.to_device(input)\n",
        "        d_b = cuda.to_device(self.biases)\n",
        "        d_k = cuda.to_device(self.kernels)\n",
        "        d_out = cuda.to_device(self.output)\n",
        "        # Thực hiện chạy function để song song hóa với grid size và block size được thiết lập\n",
        "        convolve_forward_device[grid_size, block_size](d_in, d_k, d_b, d_out)\n",
        "        cuda.synchronize()\n",
        "        # Copy dữ liệu output từ GPU sang CPU\n",
        "        self.output = d_out.copy_to_host()\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        # Step_1: Tính đạo hàm filter\n",
        "        kernel_size=self.kernels_shape[2]\n",
        "        kernels_rot_180=np.rot90(self.kernels,2,axes=(2,3))\n",
        "        kernels_rot_180 = np.ascontiguousarray(kernels_rot_180)\n",
        "\n",
        "        d_k = cuda.to_device(kernels_rot_180)\n",
        "        grid_size = (self.input.shape[0], self.depth)\n",
        "        block_size = (output_gradient.shape[1], output_gradient.shape[2])\n",
        "        kernels_gradient= np.zeros(self.kernels_shape)\n",
        "        d_k_grad = cuda.to_device(kernels_gradient)\n",
        "        d_in = cuda.to_device(self.input)\n",
        "        d_out_grad = cuda.to_device(output_gradient)\n",
        "        backward_kernel_device[grid_size, block_size](d_in, d_out_grad, d_k_grad)\n",
        "        cuda.synchronize()\n",
        "        kernels_gradient = d_k_grad.copy_to_host()\n",
        "\n",
        "        self.kernels -= learning_rate * kernels_gradient\n",
        "        self.biases -= learning_rate * np.mean(output_gradient,axis=0)\n",
        "\n",
        "        # Step_2: Tính đạo hàm input\n",
        "        output_gradient=np.pad(output_gradient,[(0,0),(kernel_size-1,kernel_size-1),(kernel_size-1,kernel_size-1),(0,0)])\n",
        "        d_out_grad = cuda.to_device(output_gradient)\n",
        "        backward_gradient= np.zeros(self.input.shape)\n",
        "        d_in_grad = cuda.to_device(backward_gradient)\n",
        "        grid_size = (self.input.shape[0], self.input_depth)\n",
        "        block_size = (self.input_shape[1], self.input_shape[2])\n",
        "        backward_input_device[grid_size, block_size](d_out_grad, d_k, d_in_grad)\n",
        "        cuda.synchronize()\n",
        "\n",
        "        backward_gradient = d_in_grad.copy_to_host()\n",
        "\n",
        "        return backward_gradient"
      ],
      "metadata": {
        "id": "zL_TfVyf0Meh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Maxpooling Layer"
      ],
      "metadata": {
        "id": "zxt1ZUZTnAL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Với max pooling layer, ta sử dụng kết hợp với numba(@jit(nopython=True) để có thể tăng tốc tốc độ của lớp này bằng cách\n",
        "  - Thay thể việc sử dụng numpy bằng cách sử dụng các dòng for để tăng tốc độ"
      ],
      "metadata": {
        "id": "W4b7kzw8f8Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def maxpooling_forward(input, kernel_size, stride):\n",
        "  n_imgs, n_rows, n_cols, c_imgs = input.shape\n",
        "  output_shape = (n_imgs, int((n_rows - kernel_size) /stride + 1),int((n_cols - kernel_size) / stride + 1), c_imgs)\n",
        "  output = np.zeros(output_shape)\n",
        "  # lưu vị trí max của từng pool trong prev_input.\n",
        "  prev_input = np.zeros((output_shape[0],output_shape[1],output_shape[2],output_shape[3],2))\n",
        "\n",
        "  for ii in range(n_imgs):\n",
        "    for c_img in range(c_imgs):\n",
        "      for rr in range(0,n_rows):\n",
        "        for cc in range(0,n_cols):\n",
        "\n",
        "          idx_r = int((rr - kernel_size) // stride + 1)\n",
        "          idx_c = int((cc - kernel_size) // stride + 1)\n",
        "          temp_in = input[ii, rr, cc, c_img]\n",
        "          temp_out = output[ii, idx_r, idx_c, c_img]\n",
        "          if (temp_in > temp_out):\n",
        "            output[ii, idx_r, idx_c, c_img] = temp_in\n",
        "            prev_input[ii,idx_r, idx_c, c_img, 0] = rr\n",
        "            prev_input[ii, idx_r, idx_c, c_img, 1] = cc\n",
        "\n",
        "  return output, prev_input\n",
        "\n",
        "@jit(nopython=True)\n",
        "def maxpooling_backward(input, prev_input, prev_shape):\n",
        "  '''\n",
        "  Input\n",
        "  input: input đã pooling\n",
        "  prev_input: chứa thông tin vị trí max trước khi pool\n",
        "  prev_shape: kích thước ban đầu trước khi pooling\n",
        "  '''\n",
        "  n_imgs, n_rows, n_cols, c_imgs = input.shape\n",
        "  output = np.zeros(prev_shape)\n",
        "\n",
        "  for ii in range(n_imgs):\n",
        "    for c_img in range(c_imgs):\n",
        "      for rr in range(n_rows):\n",
        "        for cc in range(n_cols):\n",
        "          idx = int(prev_input[ii, rr,cc,c_img, 0])\n",
        "          idy = int(prev_input[ii, rr, cc, c_img, 1])\n",
        "          output[ii, idx, idy, c_img] = input[ii, rr, cc, c_img] #gán max lại vị trí ban đầu.\n",
        "\n",
        "  return output\n",
        "\n",
        "class MaxPoolingLayer(Layer):\n",
        "  def __init__(self, kernel_size, stride):\n",
        "      self.kernel_size = kernel_size\n",
        "      self.stride = stride\n",
        "\n",
        "  def forward(self, input):\n",
        "    output, prev_input = maxpooling_forward(input, self.kernel_size, self.stride)\n",
        "\n",
        "    self.prev_input=prev_input\n",
        "    self.pre_shape=input.shape\n",
        "    return output\n",
        "\n",
        "  def backward(self,input, learning_rate):\n",
        "    '''\n",
        "    input: input đã pooling\n",
        "    prev_input: chứa thông tin vị trí max trước khi pool\n",
        "    prev_shape: kích thước ban đầu trước khi pooling\n",
        "    '''\n",
        "    return maxpooling_backward(input, self.prev_input, self.pre_shape)"
      ],
      "metadata": {
        "id": "1rdq82xgnEDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshape Layer"
      ],
      "metadata": {
        "id": "rSUyzlRFnHon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape(Layer):\n",
        "    def __init__(self):\n",
        "      pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input_shape=input.shape\n",
        "        output_shape=1\n",
        "        for i in self.input_shape[1:]:\n",
        "          output_shape*=i\n",
        "        self.output_shape=(self.input_shape[0],output_shape)\n",
        "        return np.reshape(input, self.output_shape)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        return np.reshape(output_gradient, self.input_shape)"
      ],
      "metadata": {
        "id": "x6u5t6QbnxTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fully Connected Layer"
      ],
      "metadata": {
        "id": "vhlREPVmn4Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Với Fully Connected layer, ta sử dụng kết hợp với numba(@jit(parallel=True) để có thể tăng tốc tốc độ của lớp này bằng cách\n",
        "  - Kết hợp các vòng for + thư viện numpy"
      ],
      "metadata": {
        "id": "-ajMX245glM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(parallel=True)\n",
        "def FC_forward(input, weight,bias):\n",
        "  n_imgs = input.shape[0]\n",
        "\n",
        "  res=np.zeros((n_imgs,weight.shape[1]))\n",
        "  for nn in prange(n_imgs):\n",
        "      for oo in prange(weight.shape[1]):\n",
        "          res[nn][oo]=bias[oo]\n",
        "          for ii in range(weight.shape[0]):\n",
        "            res[nn][oo]+=input[nn][ii]*weight[ii][oo]\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "_DHGDm-_nzVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(parallel=True)\n",
        "def FC_backward(input, weight, bias, output_gradient, learning_rate):\n",
        "\n",
        "  n_imgs = input.shape[0]\n",
        "  input_T=input.T\n",
        "\n",
        "  # ---------------------------------------------------\n",
        "  weight_gradient = np.zeros(weight.shape)\n",
        "\n",
        "  for ii in prange(input_T.shape[0]):\n",
        "    for oo in prange(output_gradient.shape[1]):\n",
        "      for nn in range(n_imgs):\n",
        "        weight_gradient[ii][oo]+=input_T[ii][nn]*output_gradient[nn][oo]/n_imgs\n",
        "\n",
        "  weight-=learning_rate*weight_gradient\n",
        "\n",
        "  for nn in prange(n_imgs):\n",
        "    bias-=learning_rate*output_gradient[nn]/n_imgs\n",
        "\n",
        "  weight_T=weight.T\n",
        "  input_gradient = np.zeros(input.shape)\n",
        "\n",
        "  for nn in prange(output_gradient.shape[0]):\n",
        "    for ii in prange(weight_T.shape[1]):\n",
        "      for oo in range(weight_T.shape[0]):\n",
        "        input_gradient[nn][ii]+=output_gradient[nn][oo]*weight_T[oo][ii]\n",
        "\n",
        "  return input_gradient"
      ],
      "metadata": {
        "id": "osfsE06Pn6aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCLayer(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "      self.output_size=output_size\n",
        "      np.random.seed(10)\n",
        "      self.weights = np.random.randn(input_size, output_size)/100\n",
        "      np.random.seed(10)\n",
        "      self.bias = np.random.randn(output_size)/100\n",
        "\n",
        "    def forward(self, input):\n",
        "      self.input = input\n",
        "      return FC_forward(self.input, self.weights,self.bias)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "      return FC_backward(self.input, self.weights, self.bias, output_gradient, learning_rate)"
      ],
      "metadata": {
        "id": "e_IINTt2n6gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relu Layer"
      ],
      "metadata": {
        "id": "nPqDNWr8n_to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu(Layer):\n",
        "  def __init__(self, alpha = 0.1):\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self.inputs = inputs.copy()\n",
        "    self.outputs = np.maximum(0, inputs)\n",
        "    return self.outputs\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    self.input_gradient = output_gradient.copy()\n",
        "    self.input_gradient[self.inputs < 0] = 0\n",
        "    return self.input_gradient"
      ],
      "metadata": {
        "id": "mWfJGg9roReQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax Layer"
      ],
      "metadata": {
        "id": "TmaCYPPtoUSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def softmax_forward(input):\n",
        "  n_imgs = input.shape[0]\n",
        "  output = np.zeros(input.shape)\n",
        "  for nn in range(n_imgs):\n",
        "    tmp = np.exp(input[nn] - np.max(input[nn]))\n",
        "\n",
        "    output[nn] = tmp / np.sum(tmp)\n",
        "\n",
        "  return output\n",
        "\n",
        "class Softmax(Layer):\n",
        "    def forward(self, input):\n",
        "      self.output = softmax_forward(input)\n",
        "      return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "      return output_gradient"
      ],
      "metadata": {
        "id": "fVM36JpjoDJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function"
      ],
      "metadata": {
        "id": "1nThZZTAofTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def categorical_crossentropy(y_true, y_pred):\n",
        "\n",
        "  n_imgs = y_true.shape[0]\n",
        "  num_class=y_true.shape[1]\n",
        "  res = np.zeros(y_true.shape)\n",
        "  for nn in range(n_imgs):\n",
        "    for cc in range(num_class):\n",
        "      res[nn]+=-np.log(y_pred[nn][cc])*y_true[nn][cc]\n",
        "  return res\n",
        "\n",
        "@jit(nopython=True)\n",
        "def categorical_crossentropy_backpropagation(y_true, y_pred):\n",
        "    n_imgs = y_true.shape[0]\n",
        "    size = y_true.shape[1]\n",
        "    res = np.zeros(y_true.shape)\n",
        "    for nn in range(n_imgs):\n",
        "      for cc in range(size):\n",
        "        if y_true[nn][cc]!=0:\n",
        "          res[nn][cc]=y_pred[nn][cc]-1\n",
        "        else:\n",
        "          res[nn][cc]=y_pred[nn][cc]\n",
        "    return res/n_imgs"
      ],
      "metadata": {
        "id": "L4UwO5zmodHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xây dựng Network"
      ],
      "metadata": {
        "id": "ct6Skbveojd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(network, input):\n",
        "    output = input\n",
        "    fc_time = 0\n",
        "\n",
        "    for layer in network:\n",
        "        start = time.time()\n",
        "        output = layer.forward(output)\n",
        "        layer_time = time.time() - start\n",
        "        if layer.__class__.__name__ == \"CNNLayer_Device\":\n",
        "          conv_time = layer_time\n",
        "        if layer.__class__.__name__ == \"MaxPoolingLayer\":\n",
        "            pool_time = layer_time\n",
        "        if layer.__class__.__name__ == \"FCLayer\":\n",
        "            fc_time += layer_time\n",
        "\n",
        "    return output, conv_time, pool_time, fc_time\n",
        "\n",
        "\n",
        "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000,batch_size=600,learning_rate = 0.01, verbose = True):\n",
        "  n=x_train.shape[0]\n",
        "  batch_count=n//batch_size\n",
        "  batch_index=[]\n",
        "\n",
        "  for i in range(batch_count):\n",
        "    batch_index.append((i*batch_size,(i+1)*batch_size))\n",
        "  if batch_count*batch_size !=n:\n",
        "    batch_index.append((batch_count*batch_size,n))\n",
        "  for e in range(epochs):\n",
        "    start=time.time()\n",
        "    total_time_conv = 0\n",
        "    total_time_pool = 0\n",
        "    total_time_fc = 0\n",
        "    error = 0\n",
        "\n",
        "    for i, j in batch_index:\n",
        "      output, ct, pt, fct = predict(network, x_train[i:j])\n",
        "      total_time_conv += ct\n",
        "      total_time_pool += pt\n",
        "      total_time_fc += fct\n",
        "      grad = loss_prime(y_train[i:j], output)\n",
        "      loss_batch=loss(y_train[i:j], output)\n",
        "      error += np.sum(loss_batch)/len(x_train)\n",
        "      for layer in reversed(network):\n",
        "          grad = layer.backward(grad, learning_rate)\n",
        "\n",
        "    if verbose:\n",
        "      end=time.time()\n",
        "      print(f\"{e + 1}/{epochs}, error={error}, time={end-start}\")\n",
        "      print(f\"Total Convolution Time={total_time_conv}\")\n",
        "      print(f\"Total MaxPooling Time={total_time_pool}\")\n",
        "      print(f\"Total FullyConnected Time={total_time_fc}\")\n",
        "      print(\"\")"
      ],
      "metadata": {
        "id": "oy42OY9VojEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "network = [\n",
        "    CNNLayer_Device((1, 28, 28), 3, 32),\n",
        "    Relu(),\n",
        "    MaxPoolingLayer(2, 2),\n",
        "    Reshape(),\n",
        "    FCLayer(32 * 13 * 13, 100),\n",
        "    Softmax(),\n",
        "    FCLayer(100, 10),\n",
        "    Softmax()\n",
        "]\n",
        "\n",
        "train(\n",
        "    network,\n",
        "    categorical_crossentropy,\n",
        "    categorical_crossentropy_backpropagation,\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "wBhx2RNXonXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41bd558-a090-4a7a-cf62-77e8c3e7f4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5, error=22.945242989479848, time=112.24739813804626\n",
            "Total Convolution Time=6.153479814529419\n",
            "Total MaxPooling Time=11.187533140182495\n",
            "Total FullyConnected Time=23.235563278198242\n",
            "\n",
            "2/5, error=22.3911656111799, time=111.19126558303833\n",
            "Total Convolution Time=6.15462589263916\n",
            "Total MaxPooling Time=11.031086444854736\n",
            "Total FullyConnected Time=23.189550161361694\n",
            "\n",
            "3/5, error=21.443877967818956, time=111.65131831169128\n",
            "Total Convolution Time=6.076167106628418\n",
            "Total MaxPooling Time=11.203714609146118\n",
            "Total FullyConnected Time=23.353671073913574\n",
            "\n",
            "4/5, error=20.513881781837583, time=112.0895082950592\n",
            "Total Convolution Time=6.1742939949035645\n",
            "Total MaxPooling Time=11.189940452575684\n",
            "Total FullyConnected Time=23.58342671394348\n",
            "\n",
            "5/5, error=19.702200111378566, time=109.01741003990173\n",
            "Total Convolution Time=6.234785795211792\n",
            "Total MaxPooling Time=11.163268566131592\n",
            "Total FullyConnected Time=22.751375436782837\n",
            "\n",
            "CPU times: user 14min 46s, sys: 16.1 s, total: 15min 2s\n",
            "Wall time: 9min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = predict(network, x_test)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihPSO5WeQfX",
        "outputId": "7c3d0eb9-5366-4da9-a29f-ff9bd2ad98e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18.8 s, sys: 1.83 s, total: 20.7 s\n",
            "Wall time: 14.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_label = 0\n",
        "for x, y in zip(y_pred, y_test):\n",
        "   if np.argmax(x) == np.argmax(y):\n",
        "     true_label += 1"
      ],
      "metadata": {
        "id": "mntV9XkseSx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Score: {true_label/y_pred.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3ey0MUVe3Zx",
        "outputId": "3140a394-d6c3-4321-e96c-1d3516e7fd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.8208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. Đánh giá kết quả\n"
      ],
      "metadata": {
        "id": "P3T-_g1so0Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer trong Mạng CNN"
      ],
      "metadata": {
        "id": "fmHrtiCtVfPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Layer | Tuần tự | @jit(nonpython=true) |@jit(parallel=true) | @cuda.jit |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| Convolution Layer | 12.58s |  | | 6.1534s |\n",
        "| Maxpooling Layer| 765.52s | 11.18s |  |  |\n",
        "| Fully connected layer| 27.32s | | 23.235s |  |"
      ],
      "metadata": {
        "id": "UBTxr5qnVcqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Nhận xét:** Dựa trên bảng mô tả tốc độ chạy layer ở trên của tuần tự và song song, ta thấy được tốc độ các lớp ở tuần tự đã được cải thiện một cách đáng kể đặc biệt là 2 lớp Convolution Layer(Giảm gần 50%) và  MaxPooling Layer (Giảm 98%)"
      ],
      "metadata": {
        "id": "zeu8TsV6hdPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VII. Kết luận"
      ],
      "metadata": {
        "id": "BlVXq0-nbw9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sau quá trình hoàn thành đồ án, nhóm đã học được nhiều kiến thức về lập trình song song và các áp dụng nó để có thể tối ưu các thuật toán tuần tự\n",
        "- Đồng thời, chủ đồ nhóm chọn là mạng CNN nên nhóm đã học rất nhiều và kĩ lưỡng về từng lớp có trong CNN và đặc điểm của chúng.\n",
        "- **Khó khăn:** nhóm vẫn chưa có thể áp dụng lập trình song song trên GPU ở trên các lớp như (lớp Maxpooling, lớp Fully Connected) nên vẫn chưa đưa ra được một mô hình hoàn hảo"
      ],
      "metadata": {
        "id": "omBm5Gqob9st"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIII. Tài liệu tham khảo"
      ],
      "metadata": {
        "id": "_WQNO9W6b__B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://github.com/pradeepsinngh/Parallel-Deep-Learning-in-Python\n",
        "- https://deeplearning.cs.cmu.edu/F21/document/recitation/Recitation5/CNN_Backprop_Recitation_5_F21.pdf\n",
        "- https://nttuan8.com/bai-6-convolutional-neural-network/\n",
        "- https://www.kaggle.com/talevy23/cnn-with-parallel-convolution-layers\n",
        "- http://cucis.ece.northwestern.edu/publications/pdf/LJA17.pdf"
      ],
      "metadata": {
        "id": "5dlx92HkcFrw"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}